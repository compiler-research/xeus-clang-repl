{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afdccef0-6aaa-43d6-ac29-7ea950356e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include \"kalman.hpp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6feb6a99-9580-4bf7-aa48-0a7d175494a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>\n",
    "#include <stdexcept>\n",
    "#include <vector>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebcc8af4-32b2-418b-bfbe-9ffb4ff9b0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "__global__ void matAddKernel(double* a, double* b, double* c, int rows, int cols) {\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "\n",
    "    if (col < cols && row < rows) {\n",
    "        int idx = row * cols + col;\n",
    "        c[idx] = a[idx] + b[idx];\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f7f95d9-2f3d-4600-8896-0ed4dcca1ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "__global__ void matSubKernel(double* a, double* b, double* c, int rows, int cols) {\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "\n",
    "    if (col < cols && row < rows) {\n",
    "        int idx = row * cols + col;\n",
    "        c[idx] = a[idx] - b[idx];\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00183ab5-0380-4773-a34c-053fef7782f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "__global__ void matTransposeKernel(double* a, double* c, int rows, int cols) {\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "\n",
    "    if (col < cols && row < rows) {\n",
    "        int idx_in = row * cols + col;\n",
    "        int idx_out = col * rows + row;\n",
    "        c[idx_out] = a[idx_in];\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0eff8fe-34a5-4370-b6ff-118cd4d7cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "__global__ void matvecmulKernel(double* d_mat, double* d_vec, double* d_result, int rows, int cols) {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    if (tid < rows) {\n",
    "        double sum = 0.0;\n",
    "        for (int j = 0; j < cols; j++) {\n",
    "            sum += d_mat[tid * cols + j] * d_vec[j];\n",
    "        }\n",
    "        d_result[tid] = sum;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21718df0-5f56-4122-bc1a-a368b306fdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "__global__ void matmulKernel(double* d_a, double* d_b, double* d_result, int rowsA, int colsA, int colsB) {\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    if (row < rowsA && col < colsB) {\n",
    "        double value = 0.0;\n",
    "        for (int k = 0; k < colsA; k++) {\n",
    "            value += d_a[row * colsA + k] * d_b[k * colsB + col];\n",
    "        }\n",
    "        d_result[row * colsB + col] = value;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18f843c9-9aee-4055-aae7-473c8f121037",
   "metadata": {},
   "outputs": [],
   "source": [
    "__global__ void vecsubKernel(const double* a, const double* b, double* result, int len) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < len) {\n",
    "        result[idx] = a[idx] - b[idx];\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ff06da4-1430-4720-affb-b9c8b1dc7a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "std::vector<std::vector<double>> mataddCUDA(const std::vector<std::vector<double>>& a, const std::vector<std::vector<double>>& b) {\n",
    "    int rows = a.size();\n",
    "    int cols = a[0].size();\n",
    "    \n",
    "    double* h_a = new double[rows*cols];\n",
    "    double* h_b = new double[rows*cols];\n",
    "    double* h_c = new double[rows*cols];\n",
    "    \n",
    "    for (int i = 0; i < rows; i++) {\n",
    "        for (int j = 0; j < cols; j++) {\n",
    "            h_a[i*cols + j] = a[i][j];\n",
    "            h_b[i*cols + j] = b[i][j];\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    double* d_a, * d_b, * d_c;\n",
    "    cudaMalloc((void**)&d_a, rows*cols*sizeof(double));\n",
    "    cudaMalloc((void**)&d_b, rows*cols*sizeof(double));\n",
    "    cudaMalloc((void**)&d_c, rows*cols*sizeof(double));\n",
    "\n",
    "    cudaMemcpy(d_a, h_a, rows*cols*sizeof(double), cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_b, h_b, rows*cols*sizeof(double), cudaMemcpyHostToDevice);\n",
    "\n",
    "    dim3 dimBlock(16, 16);\n",
    "    dim3 dimGrid((cols + dimBlock.x - 1) / dimBlock.x, (rows + dimBlock.y - 1) / dimBlock.y);\n",
    "    matAddKernel<<<dimGrid, dimBlock>>>(d_a, d_b, d_c, rows, cols);\n",
    "\n",
    "    cudaMemcpy(h_c, d_c, rows*cols*sizeof(double), cudaMemcpyDeviceToHost);\n",
    "\n",
    "    cudaFree(d_a);\n",
    "    cudaFree(d_b);\n",
    "    cudaFree(d_c);\n",
    "\n",
    "    std::vector<std::vector<double>> result(rows, std::vector<double>(cols));\n",
    "    for (int i = 0; i < rows; i++) {\n",
    "        for (int j = 0; j < cols; j++) {\n",
    "            result[i][j] = h_c[i*cols + j];\n",
    "        }\n",
    "    }\n",
    "\n",
    "    delete[] h_a;\n",
    "    delete[] h_b;\n",
    "    delete[] h_c;\n",
    "\n",
    "    return result;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b70f7f32-b7c2-4a1c-96a0-aea42b15f2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "std::vector<std::vector<double>> matsubCUDA(const std::vector<std::vector<double>>& a, const std::vector<std::vector<double>>& b) {\n",
    "    int rows = a.size();\n",
    "    int cols = a[0].size();\n",
    "    \n",
    "    double* h_a = new double[rows*cols];\n",
    "    double* h_b = new double[rows*cols];\n",
    "    double* h_c = new double[rows*cols];\n",
    "    \n",
    "    for (int i = 0; i < rows; i++) {\n",
    "        for (int j = 0; j < cols; j++) {\n",
    "            h_a[i*cols + j] = a[i][j];\n",
    "            h_b[i*cols + j] = b[i][j];\n",
    "        }\n",
    "    }\n",
    "\n",
    "    double* d_a, * d_b, * d_c;\n",
    "    cudaMalloc((void**)&d_a, rows*cols*sizeof(double));\n",
    "    cudaMalloc((void**)&d_b, rows*cols*sizeof(double));\n",
    "    cudaMalloc((void**)&d_c, rows*cols*sizeof(double));\n",
    "\n",
    "    cudaMemcpy(d_a, h_a, rows*cols*sizeof(double), cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_b, h_b, rows*cols*sizeof(double), cudaMemcpyHostToDevice);\n",
    "\n",
    "    dim3 dimBlock(16, 16);  \n",
    "    dim3 dimGrid((cols + dimBlock.x - 1) / dimBlock.x, (rows + dimBlock.y - 1) / dimBlock.y);\n",
    "    matSubKernel<<<dimGrid, dimBlock>>>(d_a, d_b, d_c, rows, cols);\n",
    "\n",
    "    cudaMemcpy(h_c, d_c, rows*cols*sizeof(double), cudaMemcpyDeviceToHost);\n",
    "\n",
    "    cudaFree(d_a);\n",
    "    cudaFree(d_b);\n",
    "    cudaFree(d_c);\n",
    "\n",
    "    std::vector<std::vector<double>> result(rows, std::vector<double>(cols));\n",
    "    for (int i = 0; i < rows; i++) {\n",
    "        for (int j = 0; j < cols; j++) {\n",
    "            result[i][j] = h_c[i*cols + j];\n",
    "        }\n",
    "    }\n",
    "\n",
    "    delete[] h_a;\n",
    "    delete[] h_b;\n",
    "    delete[] h_c;\n",
    "\n",
    "    return result;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86b4a452-f04c-45a4-b69b-d87bcb2e5954",
   "metadata": {},
   "outputs": [],
   "source": [
    "std::vector<std::vector<double>> mattransposeCUDA(const std::vector<std::vector<double>>& a) {\n",
    "    int rows = a.size();\n",
    "    int cols = a[0].size();\n",
    "    \n",
    "    double* h_a = new double[rows*cols];\n",
    "    double* h_c = new double[cols*rows];\n",
    "    \n",
    "    for (int i = 0; i < rows; i++) {\n",
    "        for (int j = 0; j < cols; j++) {\n",
    "            h_a[i*cols + j] = a[i][j];\n",
    "        }\n",
    "    }\n",
    "\n",
    "    double* d_a, * d_c;\n",
    "    cudaMalloc((void**)&d_a, rows*cols*sizeof(double));\n",
    "    cudaMalloc((void**)&d_c, cols*rows*sizeof(double));\n",
    "\n",
    "    cudaMemcpy(d_a, h_a, rows*cols*sizeof(double), cudaMemcpyHostToDevice);\n",
    "\n",
    "    dim3 dimBlock(16, 16);\n",
    "    dim3 dimGrid((cols + dimBlock.x - 1) / dimBlock.x, (rows + dimBlock.y - 1) / dimBlock.y);\n",
    "    matTransposeKernel<<<dimGrid, dimBlock>>>(d_a, d_c, rows, cols);\n",
    "\n",
    "    cudaMemcpy(h_c, d_c, cols*rows*sizeof(double), cudaMemcpyDeviceToHost);\n",
    "\n",
    "    cudaFree(d_a);\n",
    "    cudaFree(d_c);\n",
    "\n",
    "    std::vector<std::vector<double>> result(cols, std::vector<double>(rows));\n",
    "    for (int i = 0; i < cols; i++) {\n",
    "        for (int j = 0; j < rows; j++) {\n",
    "            result[i][j] = h_c[i*rows + j];\n",
    "        }\n",
    "    }\n",
    "\n",
    "    delete[] h_a;\n",
    "    delete[] h_c;\n",
    "\n",
    "    return result;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf413652-f71a-4b91-9e6e-5520812dc3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "// helper function: matrix inversion\n",
    "std::vector<std::vector<double>> matinverse(const std::vector<std::vector<double>>& a) {\n",
    "    size_t n = a.size();\n",
    "    \n",
    "    if (n != a[0].size()) {\n",
    "        std::cout<<\" Shape of a : \"<<a.size()<<\",\"<<a[0].size()<<\"\\n\";\n",
    "        throw std::runtime_error(\"Only square matrices are supported for inversion.\");\n",
    "    }\n",
    "\n",
    "    // Handle 1x1 matrix\n",
    "    if (n == 1) {\n",
    "        if (a[0][0] == 0) {\n",
    "            throw std::runtime_error(\"singular matrix\");\n",
    "        }\n",
    "        return {{1.0 / a[0][0]}};\n",
    "    }\n",
    "    \n",
    "    if (n == 2) {\n",
    "        double determinant = a[0][0] * a[1][1] - a[0][1] * a[1][0];\n",
    "        if (determinant == 0) {\n",
    "            throw std::runtime_error(\"singular matrix\");\n",
    "        }\n",
    "\n",
    "        std::vector<std::vector<double>> result(2, std::vector<double>(2));\n",
    "        result[0][0] = a[1][1] / determinant;\n",
    "        result[0][1] = -a[0][1] / determinant;\n",
    "        result[1][0] = -a[1][0] / determinant;\n",
    "        result[1][1] = a[0][0] / determinant;\n",
    "\n",
    "        return result;\n",
    "    }\n",
    "\n",
    "    if (n == 3) {\n",
    "        double determinant = a[0][0]*(a[1][1]*a[2][2]-a[2][1]*a[1][2]) \n",
    "                             - a[0][1]*(a[1][0]*a[2][2]-a[1][2]*a[2][0]) \n",
    "                             + a[0][2]*(a[1][0]*a[2][1]-a[1][1]*a[2][0]);\n",
    "        \n",
    "        if (determinant == 0) {\n",
    "            throw std::runtime_error(\"singular matrix\");\n",
    "        }\n",
    "\n",
    "        std::vector<std::vector<double>> result(3, std::vector<double>(3));\n",
    "\n",
    "        result[0][0] = (a[1][1] * a[2][2] - a[2][1] * a[1][2]) / determinant;\n",
    "        result[0][1] = (a[0][2] * a[2][1] - a[0][1] * a[2][2]) / determinant;\n",
    "        result[0][2] = (a[0][1] * a[1][2] - a[0][2] * a[1][1]) / determinant;\n",
    "        result[1][0] = (a[1][2] * a[2][0] - a[1][0] * a[2][2]) / determinant;\n",
    "        result[1][1] = (a[0][0] * a[2][2] - a[0][2] * a[2][0]) / determinant;\n",
    "        result[1][2] = (a[1][0] * a[0][2] - a[0][0] * a[1][2]) / determinant;\n",
    "        result[2][0] = (a[1][0] * a[2][1] - a[2][0] * a[1][1]) / determinant;\n",
    "        result[2][1] = (a[2][0] * a[0][1] - a[0][0] * a[2][1]) / determinant;\n",
    "        result[2][2] = (a[0][0] * a[1][1] - a[1][0] * a[0][1]) / determinant;\n",
    "\n",
    "        return result;\n",
    "    }\n",
    "\n",
    "    throw std::runtime_error(\"Only 2x2 and 3x3 matrices supported for inversion\");\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d925dce-377c-4d23-96d6-9c4fead297cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "std::vector<double> matvecmulCUDA(const std::vector<std::vector<double>>& a, const std::vector<double>& b) {\n",
    "    int rows = a.size();\n",
    "    int cols = a[0].size();\n",
    "\n",
    "    if (cols != b.size()) {\n",
    "        throw std::runtime_error(\"Matrix dims do not match for multiplication.\");\n",
    "    }\n",
    "\n",
    "    std::vector<double> h_mat(rows * cols);\n",
    "    for (int i = 0; i < rows; i++) {\n",
    "        for (int j = 0; j < cols; j++) {\n",
    "            h_mat[i * cols + j] = a[i][j];\n",
    "        }\n",
    "    }\n",
    "\n",
    "    double *d_mat, *d_vec, *d_result;\n",
    "    cudaMalloc((void**)&d_mat, rows * cols * sizeof(double));\n",
    "    cudaMalloc((void**)&d_vec, cols * sizeof(double));\n",
    "    cudaMalloc((void**)&d_result, rows * sizeof(double));\n",
    "\n",
    "    cudaMemcpy(d_mat, h_mat.data(), rows * cols * sizeof(double), cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_vec, b.data(), cols * sizeof(double), cudaMemcpyHostToDevice);\n",
    "\n",
    "    int blockSize = 256;\n",
    "    int gridSize = (rows + blockSize - 1) / blockSize;\n",
    "\n",
    "    matvecmulKernel<<<gridSize, blockSize>>>(d_mat, d_vec, d_result, rows, cols);\n",
    "\n",
    "    std::vector<double> result(rows);\n",
    "    cudaMemcpy(result.data(), d_result, rows * sizeof(double), cudaMemcpyDeviceToHost);\n",
    "\n",
    "    cudaFree(d_mat);\n",
    "    cudaFree(d_vec);\n",
    "    cudaFree(d_result);\n",
    "\n",
    "    return result;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69714460-9a3e-4966-9de7-5e4111fc40af",
   "metadata": {},
   "outputs": [],
   "source": [
    "std::vector<std::vector<double>> matmulCUDA(const std::vector<std::vector<double>>& a, const std::vector<std::vector<double>>& b) {\n",
    "    int rowsA = a.size();\n",
    "    int colsA = a[0].size();\n",
    "    int rowsB = b.size();\n",
    "    int colsB = b[0].size();\n",
    "\n",
    "    if (colsA != rowsB) {\n",
    "        throw std::runtime_error(\"Matrix dims do not match for multiplication.\");\n",
    "    }\n",
    "\n",
    "    std::vector<double> h_a(rowsA * colsA);\n",
    "    std::vector<double> h_b(rowsB * colsB);\n",
    "\n",
    "    for (int i = 0; i < rowsA; i++) {\n",
    "        for (int j = 0; j < colsA; j++) {\n",
    "            h_a[i * colsA + j] = a[i][j];\n",
    "        }\n",
    "    }\n",
    "\n",
    "    for (int i = 0; i < rowsB; i++) {\n",
    "        for (int j = 0; j < colsB; j++) {\n",
    "            h_b[i * colsB + j] = b[i][j];\n",
    "        }\n",
    "    }\n",
    "\n",
    "    double *d_a, *d_b, *d_result;\n",
    "    \n",
    "    cudaMalloc((void**)&d_a, rowsA * colsA * sizeof(double));\n",
    "    cudaMalloc((void**)&d_b, rowsB * colsB * sizeof(double));\n",
    "    cudaMalloc((void**)&d_result, rowsA * colsB * sizeof(double));\n",
    "\n",
    "    cudaMemcpy(d_a, h_a.data(), rowsA * colsA * sizeof(double), cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_b, h_b.data(), rowsB * colsB * sizeof(double), cudaMemcpyHostToDevice);\n",
    "\n",
    "    dim3 blockSize(16, 16);\n",
    "    dim3 gridSize((colsB + blockSize.x - 1) / blockSize.x, (rowsA + blockSize.y - 1) / blockSize.y);\n",
    "\n",
    "    matmulKernel<<<gridSize, blockSize>>>(d_a, d_b, d_result, rowsA, colsA, colsB);\n",
    "\n",
    "    std::vector<double> h_result(rowsA * colsB);\n",
    "    cudaMemcpy(h_result.data(), d_result, rowsA * colsB * sizeof(double), cudaMemcpyDeviceToHost);\n",
    "\n",
    "    cudaFree(d_a);\n",
    "    cudaFree(d_b);\n",
    "    cudaFree(d_result);\n",
    "    \n",
    "    std::vector<std::vector<double>> result(rowsA, std::vector<double>(colsB));\n",
    "    for (int i = 0; i < rowsA; i++) {\n",
    "        for (int j = 0; j < colsB; j++) {\n",
    "            result[i][j] = h_result[i * colsB + j];\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return result;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7295e929-dcfc-43be-9b3b-82e9f9fbf9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "std::vector<double> vecsubCUDA(const std::vector<double>& a, const std::vector<double>& b) {\n",
    "    int len = a.size();\n",
    "\n",
    "    double* d_a;\n",
    "    double* d_b;\n",
    "    double* d_result;\n",
    "\n",
    "    cudaMalloc((void**)&d_a, len * sizeof(double));\n",
    "    cudaMalloc((void**)&d_b, len * sizeof(double));\n",
    "    cudaMalloc((void**)&d_result, len * sizeof(double));\n",
    "\n",
    "    cudaMemcpy(d_a, a.data(), len * sizeof(double), cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_b, b.data(), len * sizeof(double), cudaMemcpyHostToDevice);\n",
    "\n",
    "    int blockSize = 256; \n",
    "    int gridSize = (len + blockSize - 1) / blockSize;\n",
    "\n",
    "    vecsubKernel<<<gridSize, blockSize>>>(d_a, d_b, d_result, len);\n",
    "\n",
    "    std::vector<double> result(len);\n",
    "    cudaMemcpy(result.data(), d_result, len * sizeof(double), cudaMemcpyDeviceToHost);\n",
    "\n",
    "    cudaFree(d_a);\n",
    "    cudaFree(d_b);\n",
    "    cudaFree(d_result);\n",
    "\n",
    "    return result;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84f29c1e-d4c2-4680-a579-14d63a2bde08",
   "metadata": {},
   "outputs": [],
   "source": [
    "void printMatrix(const std::vector<std::vector<double>>& matrix) {\n",
    "    for (size_t i = 0; i < matrix.size(); i++) {\n",
    "        for (size_t j = 0; j < matrix[i].size(); j++) {\n",
    "            std::cout << matrix[i][j] << \" \";\n",
    "        }\n",
    "        std::cout << std::endl;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d718c47-3bc6-4c7a-893c-4fedc399926d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result matrix:\n",
      "11 14 17 20 \n",
      "23 30 37 44 \n",
      "35 46 57 68 \n"
     ]
    }
   ],
   "source": [
    "// test for matrix matrix multiplication using CUDA\n",
    "std::vector<std::vector<double>> matrixA = {\n",
    "        {1.0, 2.0},\n",
    "        {3.0, 4.0},\n",
    "        {5.0, 6.0}\n",
    "    };\n",
    "\n",
    "    std::vector<std::vector<double>> matrixB = {\n",
    "        {1.0, 2.0, 3.0, 4.0},\n",
    "        {5.0, 6.0, 7.0, 8.0}\n",
    "    };\n",
    "\n",
    "    std::vector<std::vector<double>> result = matmulCUDA(matrixA, matrixB);\n",
    "\n",
    "    // Print the result\n",
    "    std::cout << \"Result matrix:\" << std::endl;\n",
    "    printMatrix(result);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4c9238f-674a-4cf8-8128-840cc7f61e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "//set up class and constructor\n",
    "KalmanFilter::KalmanFilter(\n",
    "    double dt,\n",
    "    const std::vector<std::vector<double>>& A,\n",
    "    const std::vector<std::vector<double>>& C,\n",
    "    const std::vector<std::vector<double>>& Q,\n",
    "    const std::vector<std::vector<double>>& R,\n",
    "    const std::vector<std::vector<double>>& P)\n",
    "  : A(A), C(C), Q(Q), R(R), P0(P),\n",
    "    m(C.size()), n(A.size()), dt(dt), initialized(false),\n",
    "    I(n, std::vector<double>(n)), x_hat(n), x_hat_new(n)\n",
    "{\n",
    "    for (int i = 0; i < n; i++) {\n",
    "        I[i][i] = 1.0;\n",
    "    }\n",
    "}\n",
    "\n",
    "KalmanFilter::KalmanFilter() {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd953ec6-ceed-489c-8e33-8eb7ae6bb32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "// init the kf states + measurements \n",
    "void KalmanFilter::init(double t0, const std::vector<double>& x0) {\n",
    "    x_hat = x0;\n",
    "    P = P0;\n",
    "    this->t0 = t0;\n",
    "    t = t0;\n",
    "    initialized = true;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2840f0f7-52de-4f47-a9dc-e257235df002",
   "metadata": {},
   "outputs": [],
   "source": [
    "void KalmanFilter::init() {\n",
    "    std::fill(x_hat.begin(), x_hat.end(), 0.0);\n",
    "    P = P0;\n",
    "    t0 = 0;\n",
    "    t = t0;\n",
    "    initialized = true;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea057f20-9097-4dd3-946e-ab7a383afe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "void KalmanFilter::update(const std::vector<double>& y) {\n",
    "    if (!initialized)\n",
    "        throw std::runtime_error(\"Filter is not initialized!\");\n",
    "\n",
    "    x_hat_new = matvecmulCUDA(A, x_hat);\n",
    "\n",
    "    P = mataddCUDA(matmulCUDA(matmulCUDA(A, P), mattransposeCUDA(A)), Q);\n",
    "\n",
    "    std::vector<std::vector<double>> inv = matinverse(mataddCUDA(matmulCUDA(matmulCUDA(C, P), mattransposeCUDA(C)), R));\n",
    "\n",
    "    K = matmulCUDA(matmulCUDA(P, mattransposeCUDA(C)), inv);\n",
    "    std::vector<double> temp = matvecmulCUDA(C, x_hat_new);\n",
    "    std::vector<double> difference = vecsubCUDA(y, temp);\n",
    "\n",
    "    for (size_t i = 0; i < x_hat_new.size(); i++) {\n",
    "        x_hat_new[i] += matvecmulCUDA(K, difference)[i];\n",
    "    }\n",
    "\n",
    "    P = matmulCUDA(matsubCUDA(I, matmulCUDA(K, C)), P);\n",
    "\n",
    "    x_hat = x_hat_new;\n",
    "    t += dt;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08d28163-a086-46a9-bf41-044f48530929",
   "metadata": {},
   "outputs": [],
   "source": [
    "void KalmanFilter::update(const std::vector<double>& y, double dt, const std::vector<std::vector<double>>& A) {\n",
    "    this->A = A;\n",
    "    this->dt = dt;\n",
    "    update(y);\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79ed17e5-e20a-4155-849b-41b2b9279b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "std::vector<double> generateExpandedData(const std::vector<double>& baseData, int repetitions) {\n",
    "    std::vector<double> expandedData;\n",
    "    for (int r = 0; r < repetitions; r++) {\n",
    "        for (auto val : baseData) {\n",
    "            // Add slight random perturbation to the data.\n",
    "            double perturbedValue = val + ((double)rand() / RAND_MAX - 0.5);\n",
    "            expandedData.push_back(perturbedValue);\n",
    "        }\n",
    "    }\n",
    "    return expandedData;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8938a288-fc2c-4104-82c6-added4466c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "int run_kf(int expansion_factor, bool verbose) {\n",
    "    \n",
    "    int n = 3; // Number of states\n",
    "    int m = 1; // Number of measurements\n",
    "\n",
    "    double dt = 1.0 / 30; // Time step\n",
    "    \n",
    "    std::vector<std::vector<double>> A(n, std::vector<double>(n));\n",
    "    std::vector<std::vector<double>> C(m, std::vector<double>(n));\n",
    "    std::vector<std::vector<double>> Q(n, std::vector<double>(n));\n",
    "    std::vector<std::vector<double>> R(m, std::vector<double>(m));\n",
    "    std::vector<std::vector<double>> P(n, std::vector<double>(n));\n",
    "    \n",
    "    A = {{1, dt, 0}, {0, 1, dt}, {0, 0, 1}};\n",
    "    C = {{1, 0, 0}};\n",
    "    Q = {{.05, .05, .0}, {.05, .05, .0}, {.0, .0, .0}};\n",
    "    R = {{5}};\n",
    "    P = {{.1, .1, .1}, {.1, 10000, 10}, {.1, 10, 100}};\n",
    "    \n",
    "    KalmanFilter kf(dt, A, C, Q, R, P);\n",
    "    \n",
    "    std::vector<double> measurements = {\n",
    "      1.04202710058, 1.10726790452, 1.2913511148, 1.48485250951, 1.72825901034,\n",
    "      1.74216489744, 2.11672039768, 2.14529225112, 2.16029641405, 2.21269371128,\n",
    "      2.57709350237, 2.6682215744, 2.51641839428, 2.76034056782, 2.88131780617,\n",
    "      2.88373786518, 2.9448468727, 2.82866600131, 3.0006601946, 3.12920591669,\n",
    "      2.858361783, 2.83808170354, 2.68975330958, 2.66533185589, 2.81613499531,\n",
    "      2.81003612051, 2.88321849354, 2.69789264832, 2.4342229249, 2.23464791825,\n",
    "      2.30278776224, 2.02069770395, 1.94393985809, 1.82498398739, 1.52526230354,\n",
    "      1.86967808173, 1.18073207847, 1.10729605087, 0.916168349913, 0.678547664519,\n",
    "      0.562381751596, 0.355468474885, -0.155607486619, -0.287198661013, -0.602973173813\n",
    "      };\n",
    "    \n",
    "    std::vector<double> expandedMeasurements = generateExpandedData(measurements, expansion_factor);\n",
    "    \n",
    "    std::vector<double> x0 = {expandedMeasurements[0], 0, -9.81};\n",
    "    kf.init(0, x0);\n",
    "\n",
    "    // Feed measurements into filter, output estimated states\n",
    "    std::vector<double> y(m);\n",
    "    if(verbose) {\n",
    "        std::cout << \"t = \" << 0 << \", \" << \"x_hat[0]: \";\n",
    "        for (auto& val : kf.state()) std::cout << val << \" \";\n",
    "        std::cout << std::endl;\n",
    "    }\n",
    "    \n",
    "    int i;\n",
    "    for (i = 0; i < measurements.size(); i++) {\n",
    "        y[0] = measurements[i];\n",
    "        kf.update(y);\n",
    "        if(verbose) {\n",
    "            std::cout << \"t = \" << (i + 1) * dt << \", y[\" << i << \"] = \" << y[0] << \", x_hat[\" << i << \"] = \";\n",
    "            for (auto& val : kf.state()) std::cout << val << \" \";\n",
    "            std::cout << std::endl;\n",
    "        }\n",
    "    }\n",
    "    std::cout << std::endl;\n",
    "    std::cout<<\"Exec Success, Final kf states:\";\n",
    "    for (auto& val : kf.state()) std::cout << val << \" \";\n",
    "    std::cout << std::endl;\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ea068c2-fc1f-4ad4-a2c9-aecd66cbbf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <chrono>\n",
    "auto start = std::chrono::high_resolution_clock::now();\n",
    "auto stop = std::chrono::high_resolution_clock::now();\n",
    "auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(stop - start);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e1f74bf-1118-421f-a39f-00ce72db9923",
   "metadata": {},
   "outputs": [],
   "source": [
    "int pyrun_sim(int exp_factor, bool verbose) {\n",
    "    start = std::chrono::high_resolution_clock::now();\n",
    "    run_kf(exp_factor, verbose);\n",
    "    stop = std::chrono::high_resolution_clock::now();\n",
    "    duration = std::chrono::duration_cast<std::chrono::milliseconds>(stop - start);\n",
    "    return duration.count();\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a910405-c4ff-41fa-aec5-69aa24598f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 0, x_hat[0]: 0.737686 0 -9.81 \n",
      "t = 0.0333333, y[0] = 1.04203, x_hat[0] = 0.948486 5.91215 -9.80189 \n",
      "t = 0.0666667, y[1] = 1.10727, x_hat[1] = 1.11742 5.16313 -9.80246 \n",
      "t = 0.1, y[2] = 1.29135, x_hat[2] = 1.29067 4.8479 -9.80243 \n",
      "t = 0.133333, y[3] = 1.48485, x_hat[3] = 1.46956 4.65232 -9.8015 \n",
      "t = 0.166667, y[4] = 1.72826, x_hat[4] = 1.67214 4.61508 -9.79665 \n",
      "t = 0.2, y[5] = 1.74216, x_hat[5] = 1.79217 4.11586 -9.80259 \n",
      "t = 0.233333, y[6] = 2.11672, x_hat[6] = 1.99697 4.08721 -9.78381 \n",
      "t = 0.266667, y[7] = 2.14529, x_hat[7] = 2.13716 3.7765 -9.78219 \n",
      "t = 0.3, y[8] = 2.1603, x_hat[8] = 2.23217 3.34189 -9.80002 \n",
      "t = 0.333333, y[9] = 2.21269, x_hat[9] = 2.30708 2.89745 -9.82839 \n",
      "t = 0.366667, y[10] = 2.57709, x_hat[10] = 2.44897 2.70633 -9.78267 \n",
      "t = 0.4, y[11] = 2.66822, x_hat[11] = 2.57104 2.47129 -9.74221 \n",
      "t = 0.433333, y[12] = 2.51642, x_hat[12] = 2.62117 2.05785 -9.79233 \n",
      "t = 0.466667, y[13] = 2.76034, x_hat[13] = 2.70573 1.77429 -9.76272 \n",
      "t = 0.5, y[14] = 2.88132, x_hat[14] = 2.79035 1.51648 -9.70754 \n",
      "t = 0.533333, y[15] = 2.88374, x_hat[15] = 2.85003 1.21709 -9.68495 \n",
      "t = 0.566667, y[16] = 2.94485, x_hat[16] = 2.90195 0.924505 -9.65353 \n",
      "t = 0.6, y[17] = 2.82867, x_hat[17] = 2.91129 0.544786 -9.7189 \n",
      "t = 0.633333, y[18] = 3.00066, x_hat[18] = 2.94401 0.260709 -9.67101 \n",
      "t = 0.666667, y[19] = 3.12921, x_hat[19] = 2.98862 0.0383847 -9.54536 \n",
      "t = 0.7, y[20] = 2.85836, x_hat[20] = 2.96317 -0.355458 -9.64337 \n",
      "t = 0.733333, y[21] = 2.83808, x_hat[21] = 2.92828 -0.743058 -9.73076 \n",
      "t = 0.766667, y[22] = 2.68975, x_hat[22] = 2.85989 -1.19415 -9.89987 \n",
      "t = 0.8, y[23] = 2.66533, x_hat[23] = 2.7884 -1.61706 -10.0242 \n",
      "t = 0.833333, y[24] = 2.81613, x_hat[24] = 2.75128 -1.9017 -9.95817 \n",
      "t = 0.866667, y[25] = 2.81004, x_hat[25] = 2.71309 -2.1591 -9.85946 \n",
      "t = 0.9, y[26] = 2.88322, x_hat[26] = 2.69122 -2.3396 -9.66543 \n",
      "t = 0.933333, y[27] = 2.69789, x_hat[27] = 2.63079 -2.61001 -9.59857 \n",
      "t = 0.966667, y[28] = 2.43422, x_hat[28] = 2.52104 -2.99666 -9.68334 \n",
      "t = 1, y[29] = 2.23465, x_hat[29] = 2.38245 -3.43211 -9.82404 \n",
      "t = 1.03333, y[30] = 2.30279, x_hat[30] = 2.27525 -3.73881 -9.7986 \n",
      "t = 1.06667, y[31] = 2.0207, x_hat[31] = 2.12376 -4.14204 -9.89064 \n",
      "t = 1.1, y[32] = 1.94394, x_hat[32] = 1.97709 -4.49596 -9.91916 \n",
      "t = 1.13333, y[33] = 1.82498, x_hat[33] = 1.82676 -4.82788 -9.92063 \n",
      "t = 1.16667, y[34] = 1.52526, x_hat[34] = 1.63716 -5.23716 -10.0093 \n",
      "t = 1.2, y[35] = 1.86968, x_hat[35] = 1.54514 -5.34796 -9.76318 \n",
      "t = 1.23333, y[36] = 1.18073, x_hat[36] = 1.32938 -5.77305 -9.8709 \n",
      "t = 1.26667, y[37] = 1.1073, x_hat[37] = 1.13101 -6.11758 -9.88731 \n",
      "t = 1.3, y[38] = 0.916168, x_hat[38] = 0.924926 -6.45274 -9.89309 \n",
      "t = 1.33333, y[39] = 0.678548, x_hat[39] = 0.703675 -6.7981 -9.90889 \n",
      "t = 1.36667, y[40] = 0.562382, x_hat[40] = 0.493728 -7.08693 -9.86774 \n",
      "t = 1.4, y[41] = 0.355468, x_hat[41] = 0.276462 -7.36943 -9.82262 \n",
      "t = 1.43333, y[42] = -0.155607, x_hat[42] = -0.00496317 -7.78298 -9.9046 \n",
      "t = 1.46667, y[43] = -0.287199, x_hat[43] = -0.268734 -8.1234 -9.91418 \n",
      "t = 1.5, y[44] = -0.602973, x_hat[44] = -0.551482 -8.48174 -9.93964 \n",
      "\n",
      "Exec Success, Final kf states:-0.551482 -8.48174 -9.93964 \n"
     ]
    }
   ],
   "source": [
    "pyrun_sim(10, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76110101-38eb-4100-820e-8407ba943ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exec Success, Final kf states:-0.485139 -7.98525 -9.02124 \n",
      "\n",
      "Exec Success, Final kf states:-0.436986 -7.62488 -8.35466 \n",
      "\n",
      "Exec Success, Final kf states:-0.516416 -8.21932 -9.45422 \n",
      "\n",
      "Exec Success, Final kf states:-0.476838 -7.92312 -8.90633 \n",
      "\n",
      "Exec Success, Final kf states:-0.547245 -8.45003 -9.88098 \n"
     ]
    }
   ],
   "source": [
    "%%python\n",
    "\n",
    "expand_factor = [500000, 1000000, 10000000, 20000000, 40000000]\n",
    "benchmarks = []\n",
    "\n",
    "for i in expand_factor:\n",
    "    time_kf = cppyy.gbl.pyrun_sim(int(i), 0)\n",
    "    benchmarks.append(time_kf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a47ecf6-f4e9-44b6-b72c-a935ed02fdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[880, 1584, 13726, 27178, 54014]\n"
     ]
    }
   ],
   "source": [
    "%%python\n",
    "\n",
    "print(benchmarks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CUDA (C++17)",
   "language": "CUDA",
   "name": "cuda-xcpp17"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
